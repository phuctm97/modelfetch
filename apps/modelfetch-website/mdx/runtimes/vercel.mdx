---
title: Vercel
description: Deploy MCP servers to Vercel Functions
---

The `@modelfetch/vercel` package provides ModelFetch support for deploying MCP servers to Vercel Functions, supporting both Edge Runtime and Node.js Runtime.

## Installation

```bash
npm install @modelfetch/vercel
# or
yarn add @modelfetch/vercel
# or
pnpm add @modelfetch/vercel
```

## Basic Usage

Create an API route in your Next.js app:

```typescript title="app/mcp/route.ts"
import handle from "@modelfetch/vercel";
import server from "./server";

const handler = handle(server);
export const GET = handler;
export const POST = handler;
export const DELETE = handler;
```

## API Reference

### `handle(server)`

Creates a Vercel-compatible handler from a ModelFetch server.

- **server**: The MCP server instance from `@modelcontextprotocol/sdk`

Returns a handler function compatible with Vercel's runtime.

```typescript
import handle from "@modelfetch/vercel";
import server from "./server";

const handler = handle(server);
// Use as GET, POST exports or default export
```

## Runtime Options

### Edge Runtime

The Edge Runtime provides:

- Faster cold starts
- Global edge deployment
- Web standard APIs
- Lower memory usage

```typescript
export const runtime = "edge";
```

### Node.js Runtime

The Node.js Runtime provides:

- Full Node.js API compatibility
- Larger memory limits
- Broader package ecosystem support
- File system access

```typescript
export const runtime = "nodejs";
```

## Deployment

### Using Vercel CLI

```bash
# Install Vercel CLI
npm i -g vercel

# Deploy
vercel
```

### Using Git Integration

1. Push your code to GitHub, GitLab, or Bitbucket
2. Import your project in the Vercel dashboard
3. Vercel will automatically deploy on every push

### Environment Variables

Set environment variables in the Vercel dashboard or using the CLI:

```bash
vercel env add MY_API_KEY
```

Access them in your MCP server:

```typescript
const server = new McpServer({
  title: "My MCP Server",
  name: "my-server",
  version: "1.0.0",
});

server.tool("get_api_key", "Returns the API key", {}, () => ({
  content: [
    {
      type: "text",
      text: process.env.MY_API_KEY || "Not set",
    },
  ],
}));
```

## Example Server

Here's a complete example of an MCP server for Vercel:

```typescript title="server.ts"
import { McpServer } from "@modelcontextprotocol/sdk/server/mcp.js";
import { z } from "zod";

const server = new McpServer({
  title: "Weather MCP Server",
  name: "weather-server",
  version: "1.0.0",
});

// Simple weather tool
server.tool(
  "get_weather",
  "Get the weather for a location",
  { location: z.string() },
  async ({ location }) => {
    // In a real app, you'd call a weather API
    const weather = {
      location,
      temperature: Math.floor(Math.random() * 30) + 10,
      condition: ["sunny", "cloudy", "rainy"][Math.floor(Math.random() * 3)],
    };

    return {
      content: [
        {
          type: "text",
          text: `Weather in ${weather.location}: ${weather.temperature}Â°C, ${weather.condition}`,
        },
      ],
    };
  },
);

export default server;
```

```typescript title="app/mcp/route.ts"
import handle from "@modelfetch/vercel";
import server from "./server";

const handler = handle(server);
export const GET = handler;
export const POST = handler;
export const DELETE = handler;
```

## Best Practices

### Choose the Right Runtime

- Use **Edge Runtime** for:
  - Simple MCP servers
  - Fast response times
  - Global distribution
  - Lower costs

- Use **Node.js Runtime** for:
  - Complex MCP servers
  - File system operations
  - Heavy computations
  - Specific Node.js packages

### Optimize Cold Starts

1. Keep dependencies minimal
2. Use Edge Runtime when possible
3. Implement proper caching
4. Use Vercel's ISR for static responses

### Security

1. Always validate input parameters
2. Use environment variables for secrets
3. Implement rate limiting for public endpoints
4. Enable CORS only for trusted origins

## Limitations

### Edge Runtime Limitations

- No Node.js-specific APIs
- Limited to Web Standard APIs
- 1MB response size limit
- 25 second timeout

### Node.js Runtime Limitations

- 10 second default timeout (configurable)
- 4.5MB response size limit
- Cold start latency

## Troubleshooting

### Common Issues

**Function timeout**

```typescript
// Increase timeout for Node.js runtime
export const config = {
  runtime: "nodejs",
  maxDuration: 60, // seconds
};
```

**Module not found**

```json
// Ensure dependencies are in package.json
{
  "dependencies": {
    "@modelfetch/vercel": "^0.0.1",
    "@modelcontextprotocol/sdk": "^0.0.1"
  }
}
```

**CORS errors**

```typescript
// Add CORS headers if needed
export async function OPTIONS(request: Request) {
  return new Response(null, {
    status: 200,
    headers: {
      "Access-Control-Allow-Origin": "*",
      "Access-Control-Allow-Methods": "GET, POST, OPTIONS",
      "Access-Control-Allow-Headers": "Content-Type",
    },
  });
}
```

## Next Steps

- Read the [MCP SDK documentation](https://docs.mcp.io)
- Explore [example implementations](/docs/examples)
- Learn about [MCP concepts](/docs/concepts)
